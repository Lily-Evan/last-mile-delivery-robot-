{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9142529,"sourceType":"datasetVersion","datasetId":5490804}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport skimage\nfrom skimage import io\nimport matplotlib.pyplot as plt\nimport random\nimport gc\nimport tensorflow as tf\nfrom tensorflow import keras\nimport seaborn as sns\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import confusion_matrix","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Methods for image segmentation.\ndef ll(f_path,label_dir_path):\n    comp_path = os.path.join(label_dir_path,f_path)\n    labels = []\n    with open(comp_path,\"r\") as file:\n        lines = file.readlines()\n        for line in lines:\n            labels.append(line[0])\n    return labels\n\ndef extract_from_path(image_path,dir_path):\n    image_dir_path = dir_path + \"/images/\"\n    label_dir_path = dir_path + \"/labels/\"\n    label_path = image_path[:-3]+ \"txt\"\n    labels = ll(label_path,label_dir_path)\n    return (image_dir_path + image_path),labels \n\ndef extract_from_dir(dir):\n    image_dir_path = dir + \"/images/\"\n    image_dir = os.listdir(image_dir_path)\n    comp_list = list(map(lambda p: extract_from_path(p,dir),image_dir))\n    return comp_list\n\n#Reads\ndef segment_images(segment,images_with_labels):\n    return list(map(lambda i: segment(i),images_with_labels))\n\ndef level_classes(image_label_list):\n    in_list = list(filter(lambda e: e[1] == 1,image_label_list))\n    not_in_list = list(filter(lambda e: e[1] == 0,image_label_list))[:len(in_list)]\n    comp_list = in_list + not_in_list\n    random.shuffle(comp_list)\n    return comp_list","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Segmenting images.\ntrain_dir = \"/kaggle/input/traffic-road-object-detection-polish-12k/road_detection/road_detection/train\"\nvalid_dir = \"/kaggle/input/traffic-road-object-detection-polish-12k/road_detection/road_detection/valid\"\ntest_dir = \"/kaggle/input/traffic-road-object-detection-polish-12k/road_detection/road_detection/test\"\nin_classes = [\"4\"]\n\n#This function is used to segment annotated images by their classes.\ndef in_func(image_labels):\n    image,labels = image_labels\n    if set(in_classes).issubset(set(labels)):\n        return (image,1)\n    else:\n        return (image,0)\n\ntrain_images_classes = extract_from_dir(train_dir)\nvalid_images_classes = extract_from_dir(valid_dir)\ntest_images_classes = extract_from_dir(test_dir)\n\ntrain_image_path_label = segment_images(in_func,train_images_classes)\nvalid_image_path_label = segment_images(in_func,valid_images_classes)\ntest_image_path_label = segment_images(in_func,test_images_classes)\n\nXy_train = level_classes(train_image_path_label)\nXy_valid = level_classes(valid_image_path_label)\nXy_test = level_classes(test_image_path_label)\n\ncomp_list = Xy_train + Xy_valid + Xy_test\nrandom.shuffle(comp_list)\ntotal = len(comp_list)\ntrain_count = int(0.7*total)\nvalid_count = int(0.15*total)\ntest_count = int(0.15*total)\n\nXy_train = comp_list[:train_count]\nXy_valid = comp_list[train_count+1:train_count+valid_count]\nXy_test = comp_list[train_count+valid_count+1:]\n\nX_train,y_train = zip(*Xy_train)\nX_valid,y_valid = zip(*Xy_valid)\nX_test,y_test = zip(*Xy_test)\n\nX_train = list(X_train)\nX_valid = list(X_valid)\nX_test = list(X_test)\ny_train = list(y_train)\ny_valid = list(y_valid)\ny_test = list(y_test)\n\n\nsize_arr = np.array([train_count,valid_count,test_count,total]).reshape(1,-1)\nsf = pd.DataFrame(size_arr)\n\nsf.index = [\"Images\"]\n\nsf.columns = [\"Train\",\"Validation\",\"Test\",\"Total\"]\n\nprint(sf)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Methods for preprocessing.    \ndef normalizeImage(gray_image):\n    return (gray_image - np.min(gray_image)) / (np.max(gray_image) - np.min(gray_image))\n\ndef preprocess_one(image_path):\n    image = io.imread(image_path)\n    image = skimage.transform.resize(image,(252,252))\n    image = skimage.color.rgb2gray(image)\n    image = normalizeImage(image)\n    return image\n\ndef preprocess(image_paths):\n    images = list(map(lambda i: preprocess_one(i),image_paths))\n    return images","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Visualising data.\nimage_count = 3\n\nfig,axes = plt.subplots(image_count,1,figsize=(50,50))\n\nim = X_test[:image_count]\nim_labels = y_test[:image_count]\n\nfor i in range(image_count):\n    axes[i].imshow(io.imread(im[i]))\n    s = str(im_labels[i]) + \" path:\\n\" + str(X_train[i])\n    axes[i].set_title(s)\n\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"im.clear(); del im\nim_labels.clear(); del im_labels\n\ntrain_images_classes.clear(); del train_images_classes\nvalid_images_classes.clear(); del valid_images_classes\ntest_images_classes.clear(); del test_images_classes\n\ntrain_image_path_label.clear(); del train_image_path_label\nvalid_image_path_label.clear(); del valid_image_path_label\ntest_image_path_label.clear(); del test_image_path_label\n\nXy_train.clear(); del Xy_train\nXy_valid.clear(); del Xy_valid\nXy_test.clear(); del Xy_test\ngc.collect()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_train = preprocess(X_train)\nprint(\"Preprosessing X_train done.\")\nX_valid = preprocess(X_valid)\nprint(\"Preprosessing X_valid done.\")\nX_test = preprocess(X_test)\nprint(\"Preprosessing X_test done.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\n\nmodel = keras.models.Sequential()\ninput_tensor = keras.Input(shape=(252,252,1))\nmodel.add(input_tensor)\n\nmodel.add(keras.layers.Conv2D(filters=16,kernel_size=(3,3),activation=\"relu\"))\nmodel.add(keras.layers.MaxPooling2D(pool_size=(2,2)))\n\nmodel.add(keras.layers.Conv2D(filters=32,kernel_size=(3,3),activation=\"relu\"))\nmodel.add(keras.layers.MaxPooling2D(pool_size=(2,2)))\n\nmodel.add(keras.layers.Conv2D(filters=32,kernel_size=(3,3),activation=\"relu\"))\nmodel.add(keras.layers.MaxPooling2D(pool_size=(2,2)))\n\nmodel.add(keras.layers.Conv2D(filters=32,kernel_size=(3,3),activation=\"relu\"))\nmodel.add(keras.layers.MaxPooling2D(pool_size=(2,2)))\n\nmodel.add(keras.layers.Conv2D(filters=32,kernel_size=(3,3),activation=\"relu\"))\nmodel.add(keras.layers.MaxPooling2D(pool_size=(2,2)))\n\nmodel.add(keras.layers.Flatten())\n\nmodel.add(keras.layers.Dense(252,activation=\"relu\"))\nmodel.add(keras.layers.Dense(1,activation=\"sigmoid\"))\n\nmodel.compile(optimizer=\"adam\",loss=\"binary_crossentropy\",metrics=[\"accuracy\"])\nmodel.summary()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def train_with_batch(model,X_tr,y_tr,X_val,y_val):\n    return model.fit(X_tr,y_tr,epochs=12,validation_data=(X_val,y_val),callbacks=keras.callbacks.EarlyStopping(monitor=\"val_loss\"))\n\nperformance_recap = train_with_batch(model,np.array(X_train),np.array(y_train),np.array(X_valid),np.array(y_valid))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Visualize CNN.\n#This is copied from reference 3.\nplt.plot(performance_recap.history['accuracy'], label='train_accuracy')\nplt.plot(performance_recap.history['val_accuracy'], label = 'val_accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.ylim([0.5, 1])\nplt.legend(loc='lower right')\n\ny_test_pred_cnn = model.predict(np.array(X_test))\n\ntest_loss, test_acc = model.evaluate(np.array(X_test),np.array(y_test),verbose = 1)\n\nprint(\"Test loss for CNN:\")\nprint(test_loss)\nprint(\"Test accuracy for CNN:\")\nprint(test_acc)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def round_probability_to_binary(threshold,prob):\n    if prob > threshold:\n        return 1\n    else:\n        return 0\n\ny_test_pred_cnn = list(map(lambda p: round_probability_to_binary(0.5,p),y_test_pred_cnn))   \n\nconf_mat_cnn = confusion_matrix(y_test,y_test_pred_cnn)\n\naax = plt.subplot()\n\nsns.heatmap(conf_mat_cnn, annot=True, fmt='g', ax=aax)\n\naax.set_xlabel('Predicted labels',fontsize=15)\naax.set_ylabel('True labels',fontsize=15)\naax.set_title('Confusion Matrix',fontsize=15)\naax.xaxis.set_ticklabels(['no pedestrian', 'pedestrians'],fontsize=15)\naax.yaxis.set_ticklabels(['no pedestrian', 'pedestrians'],fontsize=15)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"weights = [\"uniform\",\"distance\"]\nbestScore = 0.0\nbestK = 1\nbestWeight = \"uniform\"\n\n#making a visual representation for k to score\nuniformX = []\nuniformY = []\ndistanceX = []\ndistanceY = []\n\nX_train_KNC = np.array(X_train)\nprint(X_train_KNC.shape)\nX_train_KNC= np.reshape(X_train_KNC, (3957, -1))\nprint(X_train_KNC.shape)\n\ny_train_KNC = np.array(y_train)\n\nX_valid_KNC = np.array(X_valid)\nprint(X_valid_KNC.shape)\nX_valid_KNC = np.reshape(X_valid_KNC, (847, -1))\nprint(X_valid_KNC.shape)\n\ny_valid_KNC = np.array(y_valid)\n\n\n\nfor weight in weights:\n    print(f\"starting with {weight}\")\n    for k in range(1,100):\n        KNC = KNeighborsClassifier(n_neighbors = k, weights = weight).fit(X_train_KNC, y_train_KNC)\n        score = KNC.score(X_valid_KNC, y_valid_KNC)\n        if weight == \"uniform\":\n            uniformX.append(k)\n            uniformY.append(score)\n        else:\n            distanceX.append(k)\n            distanceY.append(score)\n            \n        if score > bestScore:\n            bestScore = score\n            bestK = k\n            bestWeight = weight\n        if k%10 == 0:\n            print(f\"{k} done\") \n        print(f\"{weight} done\")\n    \n     \nprint(\"Uniform\")\nplt.plot(uniformX,uniformY)\nplt.show()\n\nprint(\"Distance\")\nplt.plot(distanceX,distanceY)\nplt.show()\n\n\nprint(f\"The best classifier was found with parameters K: {bestK}, weight: {bestWeight} and accuracy score of: {bestScore}\")\n\n\nbestKNC = KNeighborsClassifier(n_neighbors = bestK, weights = bestWeight).fit(X_train_KNC, y_train_KNC)\ny_valid_pred = bestKNC.predict(X_valid_KNC)\nconf_matrix = confusion_matrix(y_valid_KNC, y_valid_pred)\nrecall_score = conf_matrix[1,1]/(conf_matrix[1,0]+conf_matrix[1,1])\n\ny_train_acc = bestKNC.score(X_train_KNC, y_train_KNC)\ny_valid_acc = bestKNC.score(X_valid_KNC, y_valid_KNC)\n\nprint(f\"The training accuracy for the best KNC with k: {bestK} was {y_train_acc}\")\nprint(f\"The validation accuracy for the best KNC with k: {bestK} was {y_valid_acc}\")\nprint(f\"the recall score for the validation set is {recall_score}\")\n\n\n\nax = plt.subplot()\n\nsns.heatmap(conf_matrix, annot=True, fmt='g', ax=ax)\n\nax.set_xlabel('Predicted labels',fontsize=15)\nax.set_ylabel('True labels',fontsize=15)\nax.set_title('Confusion Matrix',fontsize=15)\nax.xaxis.set_ticklabels(['no pedestrian', 'pedestrians'],fontsize=15)\nax.yaxis.set_ticklabels(['no pedestrian', 'pedestrians'],fontsize=15)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}