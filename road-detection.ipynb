{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":10162450,"sourceType":"datasetVersion","datasetId":6275430}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Class Labels:\nTraffic Light Signal\nStop Signal\nSpeedlimit Signal\nCrosswalk Signal\nCrosswalk\nPedestrian\nBus\nCar\nTruck\n","metadata":{}},{"cell_type":"markdown","source":"https://www.kaggle.com/datasets/princekhunt19/road-detection-imgs-and-labels","metadata":{}},{"cell_type":"code","source":"# Install Ultralytics library\n!pip install ultralytics","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-16T07:49:19.788723Z","iopub.execute_input":"2025-07-16T07:49:19.788898Z","iopub.status.idle":"2025-07-16T07:50:35.959468Z","shell.execute_reply.started":"2025-07-16T07:49:19.788879Z","shell.execute_reply":"2025-07-16T07:50:35.958802Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport wandb\nimport yaml\nimport zipfile\nimport matplotlib.pyplot as plt\nimport cv2\nfrom IPython.display import HTML\nfrom matplotlib import animation\nfrom tqdm import tqdm\nfrom PIL import Image\nfrom ultralytics import YOLO\nfrom IPython.display import FileLink","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-07-16T07:50:35.961468Z","iopub.execute_input":"2025-07-16T07:50:35.961761Z","iopub.status.idle":"2025-07-16T07:50:43.814615Z","shell.execute_reply.started":"2025-07-16T07:50:35.961736Z","shell.execute_reply":"2025-07-16T07:50:43.814065Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data_yaml = dict(\n    train ='/kaggle/working/dataset/train/images',\n    val ='/kaggle/working/dataset/val/images',\n    test='/kaggle/working/dataset/test/images',\n    nc = 9,\n    names =['Trafic Light Signal', 'Stop Signal', 'Speedlimit Signal', 'Crosswalk Signal', 'Crosswalk', 'Pedestrian', 'Bus', 'Car', 'Truck']\n)\nwith open('dataset.yaml', 'w') as outfile:\n    yaml.dump(data_yaml, outfile, default_flow_style=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-16T07:50:43.815233Z","iopub.execute_input":"2025-07-16T07:50:43.815565Z","iopub.status.idle":"2025-07-16T07:50:43.820854Z","shell.execute_reply.started":"2025-07-16T07:50:43.815548Z","shell.execute_reply":"2025-07-16T07:50:43.820083Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def create_zip(source_folder, destination_zip):\n    with zipfile.ZipFile(destination_zip, 'w', zipfile.ZIP_DEFLATED) as zip_ref:\n        for root, dirs, files in os.walk(source_folder):\n            for file in files:\n                file_path = os.path.join(root, file)\n                zip_ref.write(file_path, arcname=os.path.relpath(file_path, source_folder))\ndef extract_zip(zip_file, destination_folder):\n    with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n        zip_ref.extractall(destination_folder)\nsource_folder = '/kaggle/input/road-detection-imgs-and-labels'\ndestination_zip = '/kaggle/working/dataset.zip'\ndestination_folder = '/kaggle/working/'\n\ncreate_zip(source_folder, destination_zip)\nextract_zip(destination_zip, destination_folder)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-16T07:50:43.821761Z","iopub.execute_input":"2025-07-16T07:50:43.822052Z","iopub.status.idle":"2025-07-16T07:51:10.420270Z","shell.execute_reply.started":"2025-07-16T07:50:43.822024Z","shell.execute_reply":"2025-07-16T07:51:10.419538Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def create_zip(source_folder, destination_zip):\n    with zipfile.ZipFile(destination_zip, 'w', zipfile.ZIP_DEFLATED) as zip_ref:\n        for root, dirs, files in os.walk(source_folder):\n            for file in files:\n                file_path = os.path.join(root, file)\n                zip_ref.write(file_path, arcname=os.path.relpath(file_path, source_folder))\ndef extract_zip(zip_file, destination_folder):\n    with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n        zip_ref.extractall(destination_folder)\nsource_folder = '/kaggle/input/road-detection-imgs-and-labels'\ndestination_zip = '/kaggle/working/dataset.zip'\ndestination_folder = '/kaggle/working/'\n\ncreate_zip(source_folder, destination_zip)\nextract_zip(destination_zip, destination_folder)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-16T07:51:10.421118Z","iopub.execute_input":"2025-07-16T07:51:10.421480Z","iopub.status.idle":"2025-07-16T07:51:24.063264Z","shell.execute_reply.started":"2025-07-16T07:51:10.421447Z","shell.execute_reply":"2025-07-16T07:51:24.062734Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = YOLO(\"yolo11m.pt\") ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-16T07:51:24.063923Z","iopub.execute_input":"2025-07-16T07:51:24.064164Z","iopub.status.idle":"2025-07-16T07:51:26.318133Z","shell.execute_reply.started":"2025-07-16T07:51:24.064143Z","shell.execute_reply":"2025-07-16T07:51:26.317263Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!yolo task=detect mode=train model=yolo11m.pt data=dataset.yaml epochs=25 imgsz=640","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-16T07:51:26.320533Z","iopub.execute_input":"2025-07-16T07:51:26.320786Z","iopub.status.idle":"2025-07-16T08:17:57.781388Z","shell.execute_reply.started":"2025-07-16T07:51:26.320768Z","shell.execute_reply":"2025-07-16T08:17:57.780618Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!zip -r runs.zip runs/","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-16T08:17:57.782379Z","iopub.execute_input":"2025-07-16T08:17:57.782598Z","iopub.status.idle":"2025-07-16T08:18:01.949659Z","shell.execute_reply.started":"2025-07-16T08:17:57.782574Z","shell.execute_reply":"2025-07-16T08:18:01.948962Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def display_training_results(directory, file_extension=('.jpg', '.png'), images_per_row=2, image_height=10):\n    image_paths = []\n    for dirname, _, filenames in os.walk(directory):\n        for filename in filenames:\n            if filename.endswith(file_extension):\n                image_paths.append(os.path.join(dirname, filename))\n    image_paths = sorted(image_paths)\n\n    num_images = len(image_paths)\n    num_rows = (num_images + images_per_row - 1) // images_per_row  \n    figsize = (images_per_row * image_height, num_rows * image_height)\n    \n    fig, axes = plt.subplots(num_rows, images_per_row, figsize=figsize)\n    axes = axes.flatten() \n\n    for i, path in enumerate(image_paths):\n        image = Image.open(path)\n        axes[i].imshow(np.array(image))\n        axes[i].axis('off') \n\n    for j in range(len(image_paths), len(axes)):\n        axes[j].axis('off')\n\n    plt.tight_layout()\n    plt.show()\ndisplay_training_results('/kaggle/working/runs/detect/train')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-16T08:31:34.069845Z","iopub.execute_input":"2025-07-16T08:31:34.070058Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"best_path = 'runs/detect/train/weights/best.pt'\nsource = 'dataset/test/images'\n\nimage_paths = []\nfor dirname, _, filenames in os.walk(source):\n    for filename in filenames:\n        if filename.endswith('.jpg') or filename.endswith('.png'): \n            image_paths.append(os.path.join(dirname, filename))\nimage_paths = sorted(image_paths)\n\nmodel = YOLO(best_path)\n!yolo task=detect mode=predict model={best_path} conf=0.1 source={source}","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"results = model.predict(source, conf=0.1)\nresults","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"paths = []\n\nfor dirname, _, filenames in os.walk(source):\n    for filename in filenames:\n        if filename[-4:] == '.jpg' or filename[-4:] == '.png':\n            paths += [(os.path.join(dirname, filename))]\n            \npaths = sorted(paths)\ndf = pd.DataFrame(columns = range(6))\n\nfor i in range(len(results)):\n    arri = pd.DataFrame(results[i].boxes.data.cpu().numpy()).astype(float)\n    path = paths[i]\n    file = path.split('/')[-1]\n    arri = arri.assign(file = file)\n    arri = arri.assign(i = i)\n    df = pd.concat([df, arri], axis = 0)\n    \ndf.columns=['x','y','x2','y2','confidence','class','file','i']\ndisplay(df)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def draw_box(image_index):\n    image_path = paths[image_index]\n    image = cv2.imread(image_path)\n    height, width = image.shape[:2]\n    filename = image_path.split('/')[-1]\n    \n    if not df[df['file'] == filename].empty:\n        boxes = df[df['file'] == filename].reset_index(drop=True)\n\n        for box_index in range(len(boxes)):\n            label = boxes.loc[box_index, 'class']\n            x = int(boxes.loc[box_index, 'x'])\n            y = int(boxes.loc[box_index, 'y'])\n            x2 = int(boxes.loc[box_index, 'x2'])\n            y2 = int(boxes.loc[box_index, 'y2'])\n            \n            cv2.putText(\n                image, f'{label}', (x, int(y - 4)),\n                cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 255, 0), 2\n            )\n            cv2.rectangle(image, (x, y), (x2, y2), (0, 255, 0), 2) \n    \n    return image\ndef create_animation(images):\n    fig = plt.figure(figsize=(12, 8))\n    image_display = plt.imshow(cv2.cvtColor(images[0], cv2.COLOR_BGR2RGB))\n    text = plt.text(0.05, 0.05, f'Slide {0}', transform=fig.transFigure, fontsize=14, color='blue')\n    plt.axis('off')\n    plt.close()\n\n    def animate_func(frame_index):\n        image_display.set_array(cv2.cvtColor(images[frame_index], cv2.COLOR_BGR2RGB))\n        text.set_text(f'Slide {frame_index}')\n        return [image_display]\n\n    return animation.FuncAnimation(fig, animate_func, frames=len(images), interval=1000)\nannotated_images = []\n\nfor index in tqdm(range(len(paths))):\n    annotated_images.append(draw_box(index))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"anim = create_animation(annotated_images)\nHTML(anim.to_jshtml())","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}